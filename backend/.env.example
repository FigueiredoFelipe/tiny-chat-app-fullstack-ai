# LLM Configuration
# API Key for LLM service
LLM_API_KEY=your-api-key-here

# Model to use (e.g., gpt-3.5-turbo, gpt-4)
LLM_MODEL=gpt-3.5-turbo

# API URL for LLM service
LLM_API_URL=https://api.openai.com/v1

# Rate limiting configuration
RATE_LIMIT_TTL=60  # seconds
RATE_LIMIT_MAX_PER_TTL=5 # max requests per TTL